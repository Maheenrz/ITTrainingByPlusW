{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved file: csv_files/data3.csv\n",
      "Moved file: csv_files/data2.csv\n",
      "Moved file: csv_files/data.csv\n",
      "Data exported to output.csv in CSV format.\n",
      "Data exported to output.json in JSON format.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob \n",
    "import shutil \n",
    "import pandas as pd \n",
    " \n",
    " \n",
    "# Ensure backup folder exists\n",
    "if not os.path.exists(\"backup_folder\"):\n",
    "    os.makedirs(\"backup_folder\")\n",
    "     \n",
    "# Move all CSV files to a backup folder \n",
    "csv_files = glob.glob(\"csv_files/*.csv\") \n",
    "for file in csv_files: \n",
    "    shutil.move(file, \"backup_folder/\") \n",
    "    print(f\"Moved file: {file}\") \n",
    " \n",
    "# Automating Export \n",
    "def export_data(df, filename, format): \n",
    "    if format == \"csv\": \n",
    "        df.to_csv(filename, index=False) \n",
    "        print(f\"Data exported to {filename} in CSV format.\") \n",
    "    elif format == \"json\": \n",
    "        df.to_json(filename, orient=\"records\") \n",
    "        print(f\"Data exported to {filename} in JSON format.\") \n",
    "    else: \n",
    "        print(\"Unsupported format.\")          \n",
    "    \n",
    " \n",
    "# Example usage: \n",
    "# Creating a sample dataframe \n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], \n",
    "        'Age': [25, 30, 35], \n",
    "        'City': ['New York', 'Los Angeles', 'Chicago']} \n",
    " \n",
    "df = pd.DataFrame(data) \n",
    " \n",
    "# Exporting to CSV \n",
    "export_data(df, \"output.csv\", \"csv\") \n",
    " \n",
    "# Exporting to JSON \n",
    "export_data(df, \"output.json\", \"json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maheen/Documents/ITTrainingByPlusW/.venv/lib/python3.8/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored data for GOOGL\n",
      "Stored data for GOOGL\n",
      "Stored data for GOOGL\n",
      "Stored data for GOOGL\n",
      "Stored data for GOOGL\n",
      "   id symbol            timestamp        open        high         low  \\\n",
      "0   5  GOOGL  2025-02-23 06:49:04  179.634995  179.710007  179.479996   \n",
      "1   4  GOOGL  2025-02-23 06:48:03  179.634995  179.710007  179.479996   \n",
      "2   3  GOOGL  2025-02-23 06:47:02  179.634995  179.710007  179.479996   \n",
      "3   2  GOOGL  2025-02-23 06:45:59  179.634995  179.710007  179.479996   \n",
      "4   1  GOOGL  2025-02-23 06:44:58  179.634995  179.710007  179.479996   \n",
      "\n",
      "        close  volume  \n",
      "0  179.660004  652240  \n",
      "1  179.660004  652240  \n",
      "2  179.660004  652240  \n",
      "3  179.660004  652240  \n",
      "4  179.660004  652240  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Database setup\n",
    "db_name = \"stocks.db\"\n",
    "conn = sqlite3.connect(db_name)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS stock_data (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                symbol TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                open REAL,\n",
    "                high REAL,\n",
    "                low REAL,\n",
    "                close REAL,\n",
    "                volume INTEGER)''')\n",
    "conn.commit()\n",
    "\n",
    "# Function to fetch stock data\n",
    "def fetch_stock_data(symbol):\n",
    "    try:\n",
    "        stock = yf.Ticker(symbol)\n",
    "        data = stock.history(period=\"1d\", interval=\"1m\")\n",
    "\n",
    "        if data.empty:\n",
    "            print(f\"No data found for {symbol}. Skipping...\")\n",
    "            return None\n",
    "\n",
    "        latest = data.iloc[-1]  # Get the most recent price data\n",
    "        return {\n",
    "            \"symbol\": symbol,\n",
    "            \"open\": latest[\"Open\"],\n",
    "            \"high\": latest[\"High\"],\n",
    "            \"low\": latest[\"Low\"],\n",
    "            \"close\": latest[\"Close\"],\n",
    "            \"volume\": latest[\"Volume\"]\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to store data in SQLite\n",
    "def store_data(symbol):\n",
    "    stock_data = fetch_stock_data(symbol)\n",
    "    if stock_data:\n",
    "        cursor.execute('''INSERT INTO stock_data (symbol, open, high, low, close, volume)\n",
    "                          VALUES (?, ?, ?, ?, ?, ?)''',\n",
    "                       (stock_data[\"symbol\"], stock_data[\"open\"],\n",
    "                        stock_data[\"high\"], stock_data[\"low\"],\n",
    "                        stock_data[\"close\"], stock_data[\"volume\"]))\n",
    "        conn.commit()\n",
    "        print(f\"Stored data for {symbol}\")\n",
    "\n",
    "# Function to analyze stock data\n",
    "def analyze_stock(symbol):\n",
    "    df = pd.read_sql_query(\"SELECT * FROM stock_data WHERE symbol=? ORDER BY timestamp DESC LIMIT 100\", conn, params=(symbol,))\n",
    "    print(df)\n",
    "\n",
    "# Example Usage\n",
    "symbol = \"GOOGL\"  \n",
    "for _ in range(5):  # Fetch data 5 times with intervals\n",
    "    store_data(symbol)\n",
    "    time.sleep(60)  # Wait for 1 minute before fetching again\n",
    "\n",
    "analyze_stock(symbol)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to books.csv\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd \n",
    " \n",
    "URL = \"http://books.toscrape.com/\" \n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"} \n",
    " \n",
    "def get_books(url): \n",
    "    response = requests.get(url, headers=HEADERS) \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\") \n",
    "     \n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\") \n",
    "    book_list = [] \n",
    " \n",
    "    for book in books: \n",
    "        title = book.h3.a[\"title\"] \n",
    "        price = book.find(\"p\", class_=\"price_color\").text \n",
    "        stock = book.find(\"p\", class_=\"instock availability\").text.strip() \n",
    " \n",
    "        book_list.append({\"Title\": title, \"Price\": price, \"Availability\": \n",
    "                            stock}) \n",
    " \n",
    "    return book_list \n",
    " \n",
    "books_data = get_books(URL) \n",
    "df = pd.DataFrame(books_data) \n",
    "df.to_csv(\"books.csv\", index=False) \n",
    "print(\"Data saved to books.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
